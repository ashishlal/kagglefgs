{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import gc\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_csv(batch, csv_file):\n",
    "    props = dict(encoding='utf-8', index=False)\n",
    "    if not os.path.exists(csv_file):\n",
    "        batch.to_csv(csv_file, **props)\n",
    "    else:\n",
    "        batch.to_csv(csv_file, mode='a', header=False, **props)\n",
    "\n",
    "def delete_file_if_exists(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fn = '../cache/bkup/train10_t_store{}.csv'.format(1)\n",
    "df =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fn = '../cache/bkup/train10_t_store{}.csv'.format(2)\n",
    "# df2 =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>item_family</th>\n",
       "      <th>item_class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>dcount</th>\n",
       "      <th>h_type</th>\n",
       "      <th>h_desc</th>\n",
       "      <th>pd</th>\n",
       "      <th>wbe</th>\n",
       "      <th>wae</th>\n",
       "      <th>wfe</th>\n",
       "      <th>store_item_nbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, store_nbr, item_nbr, unit_sales, onpromotion, item_family, item_class, perishable, city, state, store_type, cluster, dcoilwtico, transactions, dom, mon, dow, doy, dcount, h_type, h_desc, pd, wbe, wae, wfe, store_item_nbr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.onpromotion == True) & (df.store_item_nbr == '1_105737')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df2.store_item_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2[df2.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_promo'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_promo'] = df_it['days_from_next_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_promo'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_promo'] = df_it['days_from_prev_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_event'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_event'] = df_it['days_from_next_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_event'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_event'] = df_it['days_from_prev_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_holiday'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_holiday'] = df_it['days_from_next_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_holiday'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_holiday'] = df_it['days_from_prev_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nw'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nw'] = df_it['days_from_next_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nw'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nw'] = df_it['days_from_prev_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nn'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nn'] = df_it['days_from_next_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nn'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nn'] = df_it['days_from_prev_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# days_from_next_promotion(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_holiday_test(store_num):\n",
    "    fn = '../cache/bkup/test7_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_holiday'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_holiday'] = df_it['days_from_prev_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2017-08-16')) & (df.dts <= np.datetime64('2017-08-31'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/test7_t_store{}_days_from_prev_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:45: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/54 [03:15<2:52:38, 195.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 2/54 [07:07<2:58:55, 206.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/54 [11:18<3:06:53, 219.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5/54 [19:44<3:13:17, 236.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 6/54 [23:59<3:13:40, 242.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 7/54 [28:13<3:12:29, 245.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 8/54 [32:29<3:10:36, 248.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 9/54 [36:42<3:07:32, 250.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 10/54 [40:56<3:04:11, 251.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 11/54 [45:11<3:00:47, 252.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 12/54 [49:31<2:58:15, 254.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 14/54 [58:01<2:49:50, 254.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 15/54 [1:02:14<2:45:24, 254.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 16/54 [1:06:28<2:40:56, 254.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 17/54 [1:10:42<2:36:45, 254.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 18/54 [1:14:50<2:31:22, 252.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 19/54 [1:19:04<2:27:28, 252.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 20/54 [1:23:19<2:23:37, 253.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 21/54 [1:27:29<2:18:51, 252.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 22/54 [1:31:40<2:14:24, 252.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 23/54 [1:36:16<2:13:51, 259.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 24/54 [1:40:26<2:08:09, 256.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 26/54 [1:48:52<1:59:00, 255.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 27/54 [1:53:09<1:55:01, 255.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 29/54 [2:01:33<1:45:46, 253.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 30/54 [2:05:43<1:41:00, 252.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 31/54 [2:09:56<1:36:53, 252.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 32/54 [2:14:07<1:32:26, 252.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 33/54 [2:18:16<1:27:59, 251.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 34/54 [2:22:27<1:23:44, 251.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 35/54 [2:26:41<1:19:46, 251.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 36/54 [2:30:49<1:15:16, 250.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 37/54 [2:35:01<1:11:07, 251.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 38/54 [2:39:10<1:06:48, 250.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 39/54 [2:43:21<1:02:42, 250.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 40/54 [2:47:31<58:25, 250.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 41/54 [2:51:41<54:15, 250.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 42/54 [2:55:54<50:12, 251.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 43/54 [3:00:08<46:13, 252.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 44/54 [3:04:20<42:00, 252.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 45/54 [3:08:32<37:48, 252.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 46/54 [3:12:43<33:33, 251.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 47/54 [3:16:54<29:20, 251.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 48/54 [3:21:04<25:06, 251.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 49/54 [3:25:13<20:52, 250.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 51/54 [3:34:04<12:50, 256.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 52/54 [3:38:15<08:30, 255.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 53/54 [3:42:25<04:13, 253.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [3:45:47<00:00, 237.96s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "    days_from_prev_holiday_test(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

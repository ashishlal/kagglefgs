{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import gc\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_csv(batch, csv_file):\n",
    "    props = dict(encoding='utf-8', index=False)\n",
    "    if not os.path.exists(csv_file):\n",
    "        batch.to_csv(csv_file, **props)\n",
    "    else:\n",
    "        batch.to_csv(csv_file, mode='a', header=False, **props)\n",
    "\n",
    "def delete_file_if_exists(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fn = '../cache/bkup/train10_t_store{}.csv'.format(1)\n",
    "df =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fn = '../cache/bkup/train10_t_store{}.csv'.format(2)\n",
    "# df2 =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>item_family</th>\n",
       "      <th>item_class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>dcount</th>\n",
       "      <th>h_type</th>\n",
       "      <th>h_desc</th>\n",
       "      <th>pd</th>\n",
       "      <th>wbe</th>\n",
       "      <th>wae</th>\n",
       "      <th>wfe</th>\n",
       "      <th>store_item_nbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, store_nbr, item_nbr, unit_sales, onpromotion, item_family, item_class, perishable, city, state, store_type, cluster, dcoilwtico, transactions, dom, mon, dow, doy, dcount, h_type, h_desc, pd, wbe, wae, wfe, store_item_nbr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.onpromotion == True) & (df.store_item_nbr == '1_105737')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df2.store_item_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2[df2.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_promo'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_promo'] = df_it['days_from_next_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_promo'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_promo'] = df_it['days_from_prev_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_event'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_event'] = df_it['days_from_next_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_event'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_event'] = df_it['days_from_prev_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_holiday'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_holiday'] = df_it['days_from_next_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_holiday'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_holiday'] = df_it['days_from_prev_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nw'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nw'] = df_it['days_from_next_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nw'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nw'] = df_it['days_from_prev_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nn'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nn'] = df_it['days_from_next_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nn'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nn'] = df_it['days_from_prev_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# days_from_next_promotion(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nn_test(store_num):\n",
    "    fn = '../cache/bkup/test7_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nn'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nn'] = df_it['days_from_prev_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2017-08-16')) & (df.dts <= np.datetime64('2017-08-31'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/test7_t_store{}_days_from_prev_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:45: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/54 [04:15<3:46:03, 255.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 2/54 [08:26<3:40:28, 254.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/54 [12:43<3:36:54, 255.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/54 [16:58<3:32:27, 254.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 5/54 [21:11<3:27:48, 254.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 6/54 [25:27<3:23:51, 254.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 7/54 [29:44<3:20:07, 255.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9/54 [38:11<3:10:57, 254.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 10/54 [42:30<3:07:36, 255.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 11/54 [46:43<3:02:50, 255.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 12/54 [50:57<2:58:21, 254.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 13/54 [55:09<2:53:30, 253.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 14/54 [59:21<2:48:55, 253.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 15/54 [1:03:33<2:44:27, 253.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 16/54 [1:07:47<2:40:24, 253.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 17/54 [1:12:00<2:36:04, 253.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 18/54 [1:16:12<2:31:40, 252.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 19/54 [1:20:27<2:27:51, 253.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 21/54 [1:28:55<2:19:31, 253.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 22/54 [1:33:08<2:15:08, 253.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 24/54 [1:42:02<2:09:29, 258.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 25/54 [1:46:16<2:04:27, 257.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 26/54 [1:50:28<1:59:26, 255.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 27/54 [1:54:42<1:54:47, 255.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 28/54 [1:58:51<1:49:52, 253.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 29/54 [2:03:05<1:45:36, 253.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 30/54 [2:07:13<1:40:47, 251.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 32/54 [2:15:36<1:32:12, 251.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 33/54 [2:19:48<1:28:07, 251.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 34/54 [2:23:58<1:23:42, 251.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 35/54 [2:28:10<1:19:34, 251.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 36/54 [2:32:18<1:15:10, 250.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 38/54 [2:40:40<1:06:47, 250.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 39/54 [2:44:49<1:02:31, 250.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 40/54 [2:49:00<58:26, 250.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 41/54 [2:53:11<54:16, 250.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 42/54 [2:57:17<49:51, 249.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 43/54 [3:01:28<45:47, 249.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 44/54 [3:05:38<41:39, 249.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 45/54 [3:09:49<37:31, 250.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 46/54 [3:13:57<33:17, 249.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 47/54 [3:18:10<29:12, 250.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 48/54 [3:22:17<24:57, 249.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 49/54 [3:26:30<20:52, 250.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 51/54 [3:35:10<12:40, 253.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 52/54 [3:38:25<07:51, 235.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 53/54 [3:41:18<03:37, 217.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 54/54 [3:44:08<00:00, 203.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "    days_from_prev_nn_test(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

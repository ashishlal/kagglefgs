{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import gc\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_csv(batch, csv_file):\n",
    "    props = dict(encoding='utf-8', index=False)\n",
    "    if not os.path.exists(csv_file):\n",
    "        batch.to_csv(csv_file, **props)\n",
    "    else:\n",
    "        batch.to_csv(csv_file, mode='a', header=False, **props)\n",
    "\n",
    "def delete_file_if_exists(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fn = '../cache/bkup/train10_t_store{}.csv'.format(1)\n",
    "df =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fn = '../cache/bkup/train10_t_store{}.csv'.format(2)\n",
    "# df2 =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>item_family</th>\n",
       "      <th>item_class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>dcount</th>\n",
       "      <th>h_type</th>\n",
       "      <th>h_desc</th>\n",
       "      <th>pd</th>\n",
       "      <th>wbe</th>\n",
       "      <th>wae</th>\n",
       "      <th>wfe</th>\n",
       "      <th>store_item_nbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, store_nbr, item_nbr, unit_sales, onpromotion, item_family, item_class, perishable, city, state, store_type, cluster, dcoilwtico, transactions, dom, mon, dow, doy, dcount, h_type, h_desc, pd, wbe, wae, wfe, store_item_nbr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.onpromotion == True) & (df.store_item_nbr == '1_105737')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df2.store_item_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2[df2.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_promo'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_promo'] = df_it['days_from_next_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_promo'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_promo'] = df_it['days_from_prev_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_event'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_event'] = df_it['days_from_next_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_event'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_event'] = df_it['days_from_prev_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_holiday'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_holiday'] = df_it['days_from_next_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_holiday'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_holiday'] = df_it['days_from_prev_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nw'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nw'] = df_it['days_from_next_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nw'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nw'] = df_it['days_from_prev_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nn'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nn'] = df_it['days_from_next_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nn'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nn'] = df_it['days_from_prev_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# days_from_next_promotion(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_holiday_test(store_num):\n",
    "    fn = '../cache/bkup/test7_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_holiday'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_holiday'] = df_it['days_from_next_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2017-08-16')) & (df.dts <= np.datetime64('2017-08-31'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/test7_t_store{}_days_from_next_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:45: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  2%|▏         | 1/54 [03:07<2:45:21, 187.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 2/54 [06:34<2:47:33, 193.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/54 [10:42<2:58:03, 209.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/54 [14:55<3:05:38, 222.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 5/54 [19:09<3:09:35, 232.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 6/54 [23:19<3:09:55, 237.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 7/54 [27:32<3:09:32, 241.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 8/54 [31:45<3:08:10, 245.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 9/54 [35:56<3:05:23, 247.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 10/54 [40:09<3:02:29, 248.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 11/54 [44:21<2:59:03, 249.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 12/54 [48:39<2:56:31, 252.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 13/54 [52:53<2:52:41, 252.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 15/54 [1:01:18<2:44:07, 252.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 16/54 [1:05:23<2:38:39, 250.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 17/54 [1:09:32<2:34:11, 250.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 18/54 [1:13:38<2:29:15, 248.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 19/54 [1:17:49<2:25:31, 249.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 20/54 [1:21:58<2:21:16, 249.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 21/54 [1:26:10<2:17:32, 250.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 22/54 [1:30:20<2:13:16, 249.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 23/54 [1:35:03<2:14:22, 260.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 24/54 [1:39:14<2:08:36, 257.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 25/54 [1:43:23<2:03:06, 254.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 26/54 [1:47:31<1:57:55, 252.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 27/54 [1:51:45<1:53:53, 253.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 28/54 [1:56:01<1:50:02, 253.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 29/54 [2:00:11<1:45:21, 252.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 30/54 [2:04:25<1:41:19, 253.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 31/54 [2:08:38<1:37:01, 253.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 33/54 [2:16:59<1:28:00, 251.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 34/54 [2:21:09<1:23:44, 251.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 35/54 [2:25:17<1:19:10, 250.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 36/54 [2:29:24<1:14:45, 249.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 37/54 [2:33:32<1:10:32, 248.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 38/54 [2:37:42<1:06:27, 249.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 39/54 [2:41:50<1:02:13, 248.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 40/54 [2:45:59<58:06, 249.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 41/54 [2:50:10<54:04, 249.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 43/54 [2:58:24<45:31, 248.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 44/54 [3:02:33<41:26, 248.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 45/54 [3:06:44<37:23, 249.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 46/54 [3:10:53<33:12, 249.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 47/54 [3:15:00<29:00, 248.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 48/54 [3:19:08<24:50, 248.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 49/54 [3:23:16<20:40, 248.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 50/54 [3:27:57<17:12, 258.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 51/54 [3:32:07<12:46, 255.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 52/54 [3:36:16<08:27, 253.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [3:44:26<00:00, 248.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "    days_from_next_holiday_test(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

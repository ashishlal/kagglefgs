{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import gc\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_csv(batch, csv_file):\n",
    "    props = dict(encoding='utf-8', index=False)\n",
    "    if not os.path.exists(csv_file):\n",
    "        batch.to_csv(csv_file, **props)\n",
    "    else:\n",
    "        batch.to_csv(csv_file, mode='a', header=False, **props)\n",
    "\n",
    "def delete_file_if_exists(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fn = '../cache/bkup/train10_t_store{}.csv'.format(1)\n",
    "df =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fn = '../cache/bkup/train10_t_store{}.csv'.format(2)\n",
    "# df2 =pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>item_family</th>\n",
       "      <th>item_class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>dcount</th>\n",
       "      <th>h_type</th>\n",
       "      <th>h_desc</th>\n",
       "      <th>pd</th>\n",
       "      <th>wbe</th>\n",
       "      <th>wae</th>\n",
       "      <th>wfe</th>\n",
       "      <th>store_item_nbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, store_nbr, item_nbr, unit_sales, onpromotion, item_family, item_class, perishable, city, state, store_type, cluster, dcoilwtico, transactions, dom, mon, dow, doy, dcount, h_type, h_desc, pd, wbe, wae, wfe, store_item_nbr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.onpromotion == True) & (df.store_item_nbr == '1_105737')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df2.store_item_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2[df2.onpromotion == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2.h_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_promo'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_promo'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_promo'] = df_it['days_from_next_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_promotion(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.onpromotion == True] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_promo'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_promo'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_promo'] = df_it['days_from_prev_promo'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_promo.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_promo_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_event'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_event'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_event'] = df_it['days_from_next_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_event(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Event'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_event'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_event'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_event'] = df_it['days_from_prev_event'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_event.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_event_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_holiday'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_holiday'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_holiday'] = df_it['days_from_next_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_holiday(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type == 'Holiday'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_holiday'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_holiday'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_holiday'] = df_it['days_from_prev_holiday'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_holiday.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_holiday_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nw'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nw'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nw'] = df_it['days_from_next_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nw(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nw'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nw'] = df_it['days_from_prev_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_next_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_next_nn'] = max_days\n",
    "        last_loc = 0\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc < j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = diff\n",
    "                last_loc += 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_next_nn'] = 0\n",
    "                last_loc += 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_next_nn'] = df_it['days_from_next_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_next_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_next_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nn(store_num):\n",
    "    fn = '../cache/bkup/train10_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_desc != 'Normal'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nn'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nn'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nn'] = df_it['days_from_prev_nn'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2015-01-01')) & (df.dts <= np.datetime64('2017-08-15'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/train10_t_store{}_days_from_prev_nn.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/train10_t_store{}_{}_prev_nn_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# days_from_next_promotion(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "#     days_from_prev_nw(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_from_prev_nw_test(store_num):\n",
    "    fn = '../cache/bkup/test7_t_store{}.csv'.format(store_num)\n",
    "    df =pd.read_csv(fn)\n",
    "    df['dts'] = df.date.map(np.datetime64)\n",
    "    df_min_date = np.min(df.dts)\n",
    "    df_max_date = np.min(df.dts)\n",
    "    max_days = ((df_max_date - df_min_date))/np.timedelta64(1, 'D')\n",
    "    n = 0\n",
    "    items = list(set(df.store_item_nbr))\n",
    "    for item in items:\n",
    "        n = 1\n",
    "        df_it = df[(df.store_item_nbr == item)].reset_index(drop=True)\n",
    "        \n",
    "        df_it['pe'] = 0 # promotion event\n",
    "        df_it['pe'][df_it.h_type != 'Work Day'] = 1\n",
    "        promo_indices = list(np.transpose(*np.where(df_it.pe)))\n",
    "        \n",
    "        df_it['days_from_prev_nw'] = max_days\n",
    "        last_loc = len(df_it)-1\n",
    "        for j in promo_indices:\n",
    "            promo_date = df_it.loc[j, 'dts']\n",
    "            while last_loc > j:\n",
    "                curr_date = df_it.loc[last_loc, 'dts']\n",
    "                if(curr_date == promo_date):\n",
    "                    df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                    continue\n",
    "                diff = int((promo_date - curr_date)/ np.timedelta64(1, 'D'))\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = abs(diff)\n",
    "                last_loc -= 1    \n",
    "            if last_loc == j:\n",
    "                df_it.loc[last_loc, 'days_from_prev_nw'] = 0\n",
    "                last_loc -= 1\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['id'] = df_it['id'].values\n",
    "        df1['days_from_prev_nw'] = df_it['days_from_prev_nw'].values\n",
    "        df1.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "        del df1\n",
    "    df2 = pd.DataFrame()\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        df1 = pd.read_csv(fn_tmp)\n",
    "        df2 = pd.concat([df2, df1], axis=0)\n",
    "    df2 = df2.sort('id')\n",
    "    df = df[(df.dts >= np.datetime64('2017-08-16')) & (df.dts <= np.datetime64('2017-08-31'))]\n",
    "    min_id = df.iloc[0]['id']\n",
    "    df2 = df2[df2.id >= min_id]\n",
    "    assert(len(df) == len(df2))\n",
    "    # assert(df.id == df2.id)\n",
    "    s = sum(df2.isnull().any()==True) # print NA\n",
    "    print(s)\n",
    "    if s > 0:\n",
    "        print(df2.isnull().sum())\n",
    "    fn_tmp = '../cache/test7_t_store{}_days_from_prev_nw.csv'.format(store_num)\n",
    "    delete_file_if_exists(fn_tmp)\n",
    "    df2.to_csv(fn_tmp, float_format='%.5f', index=False)\n",
    "    del df2\n",
    "    del df\n",
    "    for item in items:\n",
    "        fn_tmp = '../cache/test7_t_store{}_{}_prev_nw_tmp.csv'.format(store_num, item)\n",
    "        delete_file_if_exists(fn_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:45: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/54 [09:46<4:10:57, 289.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/54 [14:55<4:10:58, 295.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/54 [20:01<4:08:45, 298.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 5/54 [25:08<4:05:57, 301.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 6/54 [30:15<4:02:11, 302.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 7/54 [35:19<3:57:31, 303.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 8/54 [40:24<3:52:50, 303.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 9/54 [45:34<3:49:09, 305.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 10/54 [50:38<3:43:46, 305.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 11/54 [55:42<3:38:24, 304.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 13/54 [1:05:52<3:28:15, 304.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 14/54 [1:10:56<3:22:59, 304.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 15/54 [1:16:04<3:18:30, 305.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 16/54 [1:21:00<3:11:38, 302.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 17/54 [1:26:02<3:06:35, 302.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 18/54 [1:31:03<3:01:14, 302.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 20/54 [1:41:02<2:50:18, 300.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 21/54 [1:46:07<2:46:03, 301.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 22/54 [1:51:17<2:42:16, 304.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 23/54 [1:56:18<2:36:37, 303.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 24/54 [2:01:21<2:31:32, 303.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 25/54 [2:06:22<2:26:16, 302.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 26/54 [2:11:23<2:20:55, 301.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 28/54 [2:21:25<2:10:38, 301.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 29/54 [2:26:23<2:05:09, 300.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 30/54 [2:31:23<2:00:07, 300.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 31/54 [2:36:24<1:55:12, 300.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 32/54 [2:41:24<1:50:04, 300.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 33/54 [2:46:24<1:45:02, 300.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 34/54 [2:51:24<1:40:06, 300.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 35/54 [2:56:25<1:35:08, 300.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 36/54 [3:01:31<1:30:34, 301.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 37/54 [3:06:29<1:25:17, 301.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 38/54 [3:11:30<1:20:12, 300.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 39/54 [3:16:30<1:15:07, 300.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 40/54 [3:21:24<1:09:40, 298.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 41/54 [3:26:25<1:04:53, 299.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 42/54 [3:31:28<1:00:04, 300.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 44/54 [3:40:44<47:50, 287.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 45/54 [3:44:18<39:46, 265.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 46/54 [3:47:43<32:57, 247.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 48/54 [3:54:17<22:10, 221.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 49/54 [3:57:35<17:51, 214.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 50/54 [4:00:52<13:57, 209.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 51/54 [4:04:09<10:17, 205.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 53/54 [4:10:44<03:21, 201.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 54/54 [4:13:57<00:00, 198.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,55)):\n",
    "#     days_from_next_promotion(i)\n",
    "#     days_from_prev_promotion(i)\n",
    "#     days_from_next_event(i)\n",
    "#     days_from_prev_event(i)\n",
    "#     days_from_next_holiday(i)\n",
    "#     days_from_prev_holiday(i)\n",
    "#     days_from_next_nw(i)\n",
    "    days_from_prev_nw_test(i)\n",
    "#     days_from_next_nn(i)\n",
    "#     days_from_prev_nn(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
